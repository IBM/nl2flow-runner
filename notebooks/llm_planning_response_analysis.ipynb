{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# write jsonl file\n",
    "from ai_profiling.generators.planning_data_generator_datatypes import (\n",
    "    ValidationLLMResponsePlanningData,\n",
    ")\n",
    "from ai_profiling.helpers.file_helper.file_helper import (\n",
    "    get_base_model_from_json,\n",
    "    get_files_in_folder,\n",
    ")\n",
    "\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "\n",
    "planning_data = {\"verbose\": [], \"concise\": []}\n",
    "\n",
    "def has_model_to_ignore(llm_response_json_evaluation_datum:ValidationLLMResponsePlanningData, to_ignore: List[str]) -> bool:\n",
    "    if llm_response_json_evaluation_datum.llm_response_planning_data is not None:\n",
    "        for to_ignore_name in to_ignore:\n",
    "            if to_ignore_name.lower() in llm_response_json_evaluation_datum.llm_response_planning_data.llm_response.llm_model_id.lower():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "folder_path = \"/Users/jungkookang/Downloads/nl2flow/output/plan/llm_plan_evaluation/long\"\n",
    "file_paths = get_files_in_folder(folder_path=Path(folder_path), file_extension=\"json\")\n",
    "\n",
    "to_ignore=[\"codellama\", \"deepseek-coder\"]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    llm_response_json_evaluation_datum = get_base_model_from_json(\n",
    "        file_path=file_path, base_model=ValidationLLMResponsePlanningData\n",
    "    )\n",
    "    if not has_model_to_ignore(llm_response_json_evaluation_datum, to_ignore):\n",
    "        planning_data[\"verbose\"].append(llm_response_json_evaluation_datum)\n",
    "\n",
    "\n",
    "folder_path = \"/Users/jungkookang/Downloads/nl2flow/output/plan/llm_plan_evaluation/short\"\n",
    "file_paths = get_files_in_folder(folder_path=Path(folder_path), file_extension=\"json\")\n",
    "\n",
    "for file_path in file_paths:\n",
    "    llm_response_json_evaluation_datum = get_base_model_from_json(\n",
    "        file_path=file_path, base_model=ValidationLLMResponsePlanningData\n",
    "    )\n",
    "    if not has_model_to_ignore(llm_response_json_evaluation_datum, to_ignore):\n",
    "        planning_data[\"concise\"].append(llm_response_json_evaluation_datum)\n",
    "\n",
    "print(f\"Data points: Long: {len(planning_data['verbose'])}, Short: {len(planning_data['concise'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all data to each llm model\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pprint\n",
    "from typing import Dict, List\n",
    "\n",
    "llm_bin_meta = {}\n",
    "llm_bin_meta_no_plan = {}\n",
    "llm_bin_meta_plan = {}\n",
    "\n",
    "long_plan_models = set()\n",
    "for category in planning_data.keys():\n",
    "    llm_bin: Dict[str, Dict[str, int]] = defaultdict(\n",
    "        lambda: {\"total\": 0, \"optimal\": 0, \"sound\": 0, \"valid\": 0, \"long_plan\": 0, \"plan_length\": defaultdict(lambda: 0), \"optimal_plan_length\": defaultdict(lambda: 0), \"prompt_length_total\": 0}\n",
    "    )\n",
    "    llm_bin_no_plan: Dict[str, Dict[str, int]] = defaultdict(lambda: {\"total\": 0, \"optimal\": 0, \"sound\": 0, \"valid\": 0})\n",
    "    llm_bin_plan: Dict[str, Dict[str, int]] = defaultdict(lambda: {\"total\": 0, \"optimal\": 0, \"sound\": 0, \"valid\": 0})\n",
    "    for llm_response_planning_evaluation_unit in planning_data[category]:\n",
    "        llm_model_id = (llm_response_planning_evaluation_unit.llm_response_planning_data.llm_response.llm_model_id).split(\"/\")[-1]\n",
    "        llm_model_id = llm_model_id.replace(\"3-1\", \"3.1\").replace(\"3-3\", \"3.3\")\n",
    "        llm_bin[llm_model_id][\"total\"] += 1\n",
    "        llm_bin[llm_model_id][\"prompt_length_total\"] += len(llm_response_planning_evaluation_unit.llm_response_planning_data.planning_prompt)\n",
    "        \n",
    "        optimal_plan_length = llm_response_planning_evaluation_unit.llm_response_planning_data.pddl_generator_output.planning_datum_tag.length_of_sequence\n",
    "        llm_bin[llm_model_id][\"optimal_plan_length\"][optimal_plan_length] += 1\n",
    "        is_no_plan = (\n",
    "            optimal_plan_length\n",
    "            == 0\n",
    "        )\n",
    "\n",
    "        if is_no_plan:\n",
    "            llm_bin_no_plan[llm_model_id][\"total\"] += 1\n",
    "            optimal_plan_length = 0\n",
    "        else:\n",
    "            llm_bin_plan[llm_model_id][\"total\"] += 1\n",
    "\n",
    "        \n",
    "\n",
    "        if llm_response_planning_evaluation_unit.llm_plan is not None:\n",
    "            plan_length = len(llm_response_planning_evaluation_unit.llm_plan)\n",
    "            llm_bin[llm_model_id][\"plan_length\"][plan_length] += 1\n",
    "            if plan_length > 10:\n",
    "                long_plan_models.add(llm_model_id)\n",
    "                llm_bin[llm_model_id][\"long_plan\"] +=1\n",
    "\n",
    "\n",
    "        # soundness\n",
    "        if (\n",
    "            llm_response_planning_evaluation_unit.report_soundness is not None\n",
    "            and llm_response_planning_evaluation_unit.report_soundness.determination\n",
    "        ):\n",
    "            llm_bin[llm_model_id][\"sound\"] += 1\n",
    "            if is_no_plan:\n",
    "                llm_bin_no_plan[llm_model_id][\"sound\"] += 1\n",
    "            else:\n",
    "                llm_bin_plan[llm_model_id][\"sound\"] += 1\n",
    "\n",
    "        # handle no plan case\n",
    "        if (\n",
    "            llm_response_planning_evaluation_unit.llm_response_planning_data.pddl_generator_output.planning_datum_tag.length_of_sequence\n",
    "            == 0\n",
    "        ):  # no plan case\n",
    "            if (llm_response_planning_evaluation_unit.llm_plan is not None) and (\n",
    "                len(llm_response_planning_evaluation_unit.llm_plan) == 0\n",
    "            ):\n",
    "                llm_bin[llm_model_id][\"valid\"] += 1\n",
    "                llm_bin[llm_model_id][\"optimal\"] += 1\n",
    "                llm_bin_no_plan[llm_model_id][\"valid\"] += 1\n",
    "                llm_bin_no_plan[llm_model_id][\"optimal\"] += 1\n",
    "        else:  # plan exists\n",
    "            if (\n",
    "                llm_response_planning_evaluation_unit.report_validity is not None\n",
    "                and llm_response_planning_evaluation_unit.report_validity.determination\n",
    "            ):\n",
    "                llm_bin[llm_model_id][\"valid\"] += 1\n",
    "                llm_bin_plan[llm_model_id][\"valid\"] += 1\n",
    "            if (\n",
    "                llm_response_planning_evaluation_unit.report_optimality is not None\n",
    "                and llm_response_planning_evaluation_unit.report_optimality.determination\n",
    "            ):\n",
    "                llm_bin[llm_model_id][\"optimal\"] += 1\n",
    "                llm_bin_plan[llm_model_id][\"optimal\"] += 1\n",
    "\n",
    "    for model_name in llm_bin.keys():\n",
    "        llm_bin[model_name][\"long_plan_fraction\"] = llm_bin[model_name][\"long_plan\"] / llm_bin[model_name][\"total\"]\n",
    "        llm_bin[model_name][\"avg_prompt_length\"] = llm_bin[model_name][\"prompt_length_total\"] / llm_bin[model_name][\"total\"]\n",
    "    \n",
    "    llm_bin_meta[category] = deepcopy(llm_bin)\n",
    "    llm_bin_meta_no_plan[category] = deepcopy(llm_bin_no_plan)\n",
    "    llm_bin_meta_plan[category] = deepcopy(llm_bin_plan)\n",
    "\n",
    "\n",
    "pprint.pp(long_plan_models)\n",
    "\n",
    "pprint.pp(llm_bin_meta)\n",
    "# pprint.pp(llm_bin_meta_no_plan)\n",
    "# pprint.pp(llm_bin_meta_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from ai_profiling.helpers.file_helper.file_helper import write_json_from_dict\n",
    "\n",
    "result_distributions = {}\n",
    "model_names = list(llm_bin_meta[\"verbose\"].keys())\n",
    "for model_name in model_names:\n",
    "    dists = []\n",
    "    for prompt_style in llm_bin_meta.keys():\n",
    "        sample = []\n",
    "        for plan_length, frequency in llm_bin_meta[prompt_style][model_name][\"plan_length\"].items():\n",
    "            sample += [plan_length for _ in range(frequency)]\n",
    "        dists.append(sample)\n",
    "    statistic, p_value = stats.ks_2samp(dists[0], dists[1])\n",
    "    u_statistic, u_p_value= stats.mannwhitneyu(dists[0], dists[1])\n",
    "    result_distributions[model_name] = {\"k-stat\": float(statistic), \"k-p_value\": float(p_value), \"u-stat\": float(u_statistic), \"u-p_value\": float(u_p_value)}\n",
    "\n",
    "write_json_from_dict(file_path=Path(os.path.join(\"output\", \"distribution\", \"plan_length_distribution.json\")), dic=result_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from copy import deepcopy\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def process_model_obj(model_input, to_ignore):\n",
    "    new_model_input = {}\n",
    "    for model_name, val in model_input.items():\n",
    "        new_model_name = model_name.split(\"/\")[-1]\n",
    "        if \"DeepSeek-V3\" == new_model_name:\n",
    "            new_model_name += \"(685b, fp8)\"\n",
    "        new_name = new_model_name.strip().lower()\n",
    "\n",
    "        should_ignore = False\n",
    "        for name_to_ignore in to_ignore:\n",
    "            if name_to_ignore in new_name:\n",
    "                should_ignore = True\n",
    "                break\n",
    "        if not should_ignore:\n",
    "            new_model_input[new_name] = deepcopy(val)\n",
    "\n",
    "    return collections.OrderedDict(sorted(new_model_input.items(), key=lambda it: str(it[0]), reverse=False)) # collections.OrderedDict(sorted(llm_bin.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from typing import Any, Set\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def make_len_length_chart_subplot(\n",
    "    llm_bin_input,\n",
    "    output_folder_path: str,\n",
    "    max_y: int,\n",
    "    to_ignore: List[str] = [],\n",
    "    skip_interval: int = 1,\n",
    "    max_x: Optional[float] = None,\n",
    "    file_extention: str = \"png\",\n",
    "    select_idx: int = 0,\n",
    ") -> None:\n",
    "    def get_length_arr(tmp_dict, min_val, max_val):\n",
    "        lst = []\n",
    "        for val in range(min_val, max_val + 1):\n",
    "            tmp_val = tmp_dict[val] if val in tmp_dict else 0\n",
    "            lst.append(tmp_val)\n",
    "\n",
    "        return np.array(lst)\n",
    "\n",
    "    key_name = \"plan_length\"\n",
    "    optimal_key_name = \"optimal_plan_length\"\n",
    "    new_llm_bin = deepcopy(llm_bin_input)\n",
    "    llm_bin = {category: process_model_obj(val, to_ignore) for category, val in new_llm_bin.items()}\n",
    "\n",
    "    # find min, max length\n",
    "    max_plan_length = -1\n",
    "    optimal_max_plan_length = -1\n",
    "    for idx, category in enumerate(llm_bin.keys()):\n",
    "        tmp_dict = llm_bin[category]\n",
    "\n",
    "        for model_name, val_dict in tmp_dict.items():\n",
    "            length_dict = val_dict[key_name]\n",
    "            optimal_length_dict = val_dict[optimal_key_name]\n",
    "            for plan_length in length_dict.keys():\n",
    "                max_plan_length = max(max_plan_length, plan_length)\n",
    "            for plan_length in optimal_length_dict.keys():\n",
    "                optimal_max_plan_length = max(optimal_max_plan_length, plan_length)\n",
    "\n",
    "    if select_idx == -1:  # length comparison chart\n",
    "        total_data_dict: Dict[str, Dict[str, Any]] = {}\n",
    "        model_names: Set[str] = set()\n",
    "        for idx, category in enumerate(llm_bin.keys()):\n",
    "            tmp_dict = llm_bin[category]\n",
    "            # plan length\n",
    "            x_lables = tuple(range(0, max_plan_length + 1))\n",
    "            max_length_observed = max(max_plan_length, optimal_max_plan_length)\n",
    "            # collect model names\n",
    "            for model_name in tmp_dict.keys():\n",
    "                model_names.add(model_name)\n",
    "            data_dict = {\n",
    "                model_name: get_length_arr(val_dict[key_name], min_val=0, max_val=max_length_observed)\n",
    "                for model_name, val_dict in tmp_dict.items()\n",
    "            }\n",
    "            # optimal_data_dict = {model_name: get_length_arr(val_dict[optimal_key_name], min_val=0, max_val=max_length_observed) for model_name, val_dict in tmp_dict.items()}\n",
    "            # num_subplots = len(data_dict) + 1\n",
    "            total_data_dict[category] = {\"plan_lengths\": data_dict, \"x_labels\": np.arange(len(x_lables))}\n",
    "\n",
    "        columns = 2\n",
    "        rows = len(model_names)\n",
    "        fig, ax = plt.subplots(rows, columns, figsize=(10, 20))\n",
    "\n",
    "        model_names_list = list(model_names)\n",
    "        model_names_list.sort()\n",
    "\n",
    "        for col, category in enumerate(total_data_dict):\n",
    "            for row, model_name in enumerate(model_names_list):\n",
    "                plan_length_distribution = total_data_dict[category][\"plan_lengths\"][model_name]\n",
    "                x = total_data_dict[category][\"x_labels\"]\n",
    "                # plot\n",
    "                rects = ax[row, col].bar(x, plan_length_distribution)\n",
    "                ax[row, col].bar_label(rects, padding=3, fontsize=8)  # fmt=\"%.2f\"\n",
    "\n",
    "                pre_fix = category.capitalize() + \" prompt style\" + \"\\n\\n\" if row == 0 else \"\"\n",
    "\n",
    "                ax[row, col].set_title(pre_fix + f\"{model_name.capitalize()}\", y=1)\n",
    "                max_x_tmp = (max_plan_length + 1) if max_x is None else max_x\n",
    "                ax[row, col].set_ylim(0, max_y)\n",
    "                ax[row, col].set_xlim(0, int(max_x_tmp))\n",
    "                ax[row, col].tick_params(axis=\"x\", labelsize=12)\n",
    "                ax[row, col].tick_params(axis=\"y\", labelsize=12)\n",
    "                ax[row, col].set_xlabel(\"Plan length\", fontsize=12)\n",
    "                ax[row, col].set_ylabel(\"Frequency\", fontsize=12)\n",
    "                ax[row, col].spines[[\"right\", \"top\"]].set_visible(False)\n",
    "                ax[row, col].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(output_folder_path, (\"plan_length_comparison\" + \".\" + file_extention)), bbox_inches=\"tight\"\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    else: # only for optimal plan length plot\n",
    "        for idx, category in enumerate(llm_bin.keys()):\n",
    "            if idx != select_idx:\n",
    "                continue\n",
    "\n",
    "            tmp_dict = llm_bin[category]\n",
    "            # plan length\n",
    "            x_lables = tuple(range(0, max_plan_length + 1))\n",
    "\n",
    "            max_length_observed = max(max_plan_length, optimal_max_plan_length)\n",
    "            data_dict = {\n",
    "                model_name: get_length_arr(val_dict[key_name], min_val=0, max_val=max_length_observed)\n",
    "                for model_name, val_dict in tmp_dict.items()\n",
    "            }\n",
    "            optimal_data_dict = {\n",
    "                model_name: get_length_arr(val_dict[optimal_key_name], min_val=0, max_val=max_length_observed)\n",
    "                for model_name, val_dict in tmp_dict.items()\n",
    "            }\n",
    "            num_subplots = len(data_dict) + 1\n",
    "            columns = 2 if num_subplots > 1 else 1\n",
    "            rows = ceil(num_subplots / 2)\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(4, 4))  # figsize=(12, 8) height_ratios=[rows,1]\n",
    "\n",
    "            x = np.arange(len(x_lables))  # the label locations\n",
    "            # counter = 0\n",
    "            # for attribute, measurement in data_dict.items():\n",
    "            #     row = int(counter / 2)\n",
    "            #     col = counter % 2\n",
    "            #     rects = ax[row, col].bar(x, measurement)\n",
    "            #     ax[row, col].bar_label(rects, padding=3, fontsize=8)  # fmt=\"%.2f\"\n",
    "            #     ax[row, col].set_title(f\"{attribute.capitalize()}\", y=1)\n",
    "            #     max_x_tmp = (max_plan_length + 1) if max_x is None else max_x\n",
    "            #     ax[row, col].set_ylim(0, max_y)\n",
    "            #     ax[row, col].set_xlim(0, int(max_x_tmp))\n",
    "            #     ax[row, col].tick_params(axis=\"x\", labelsize=12)\n",
    "            #     ax[row, col].tick_params(axis=\"y\", labelsize=12)\n",
    "            #     ax[row, col].set_xlabel(\"Plan length\", fontsize=12)\n",
    "            #     ax[row, col].set_ylabel(\"Frequency\", fontsize=12)\n",
    "            #     ax[row, col].spines[[\"right\", \"top\"]].set_visible(False)\n",
    "            #     ax[row, col].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            #     counter += 1\n",
    "\n",
    "            # Optimal plan length\n",
    "            for attribute, measurement in optimal_data_dict.items():\n",
    "                row = 0\n",
    "                col = 0\n",
    "                rects = ax.bar(x, measurement)\n",
    "                ax.bar_label(rects, padding=3, fontsize=8)  # fmt=\"%.2f\"\n",
    "                # ax.set_title(\"Optimal plan\", y=1)\n",
    "                max_x_tmp = (max_plan_length + 1) if max_x is None else max_x\n",
    "                ax.set_ylim(0, max_y)\n",
    "                ax.set_xlim(0, int(max_x_tmp))\n",
    "                ax.tick_params(axis=\"x\", labelsize=12)\n",
    "                ax.tick_params(axis=\"y\", labelsize=12)\n",
    "                ax.set_xlabel(\"Plan length\", fontsize=12)\n",
    "                ax.set_ylabel(\"Frequency\", fontsize=12)\n",
    "                ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "                ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "                # ax[rows-1, columns -1].set_visible(False)\n",
    "                break\n",
    "\n",
    "        # if counter < (rows * columns):\n",
    "        #     ax[rows-1, columns -1].set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder_path, (\"plan_length_optimal\" + \".\" + file_extention)), bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt effect on plan length\n",
    "make_len_length_chart_subplot(llm_bin_input=llm_bin_meta, output_folder_path=\"output/plot\", max_y=700, to_ignore=[\"codellama\", \"deepseek-coder\"], max_x=15, select_idx=-1) # select index determines verbose or concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal plan length\n",
    "make_len_length_chart_subplot(llm_bin_input=llm_bin_meta, output_folder_path=\"output/plot\", max_y=700, to_ignore=[\"codellama\", \"deepseek-coder\"], max_x=15, select_idx=0) # select index determines verbose or concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_planning_chart_multi_rev(\n",
    "    llm_bin_input,\n",
    "    file_name_path: str,\n",
    "    is_no_plan: bool = False,\n",
    ") -> None:\n",
    "    new_llm_bin = deepcopy(llm_bin_input)\n",
    "    # llm_bin: soundness, validity, optimality -> long, short -> model\n",
    "    llm_bin2 = {}\n",
    "    include_categories = {\"optimal\": \"Optimality\", \"valid\": \"Validity\", \"sound\": \"Soundness\"}\n",
    "    for prompt_type, obj in new_llm_bin.items():\n",
    "\n",
    "        for model_name, obj2 in obj.items():\n",
    "            total = obj2[\"total\"]\n",
    "            for quality, metric in obj2.items():\n",
    "                if quality not in include_categories:\n",
    "                    continue\n",
    "                if quality == \"total\":\n",
    "                    continue\n",
    "                if quality not in llm_bin2:\n",
    "                    llm_bin2[quality] = {}\n",
    "                if prompt_type not in llm_bin2[quality]:\n",
    "                    llm_bin2[quality][prompt_type] = {}\n",
    "                llm_bin2[quality][prompt_type][model_name] = metric / total\n",
    "    rows = len(llm_bin2)\n",
    "    cols = len(llm_bin2[\"valid\"])\n",
    "    fig, ax = plt.subplots(1, cols, figsize=(10, 5)) if is_no_plan else plt.subplots(rows, cols, figsize=(10, 10))\n",
    "    fig.tight_layout()\n",
    "    handles = None\n",
    "    labels = None\n",
    "\n",
    "\n",
    "    for quality, obj in llm_bin2.items():\n",
    "        if is_no_plan and quality != \"valid\":\n",
    "            continue\n",
    "        row = 0\n",
    "        if not is_no_plan:\n",
    "            if quality == \"valid\":\n",
    "                row = 1\n",
    "            elif quality == \"optimal\":\n",
    "                row = 2\n",
    "        \n",
    "        for prompt_type, obj2 in obj.items():\n",
    "            col = 0\n",
    "            if prompt_type == \"concise\":\n",
    "                col = 1\n",
    "            \n",
    "            width = 0.25  # the width of the bars\n",
    "            multiplier = 0\n",
    "            model_names = list(obj2.keys())\n",
    "            model_names.sort()\n",
    "            values = [obj2[model_name] for model_name in model_names]\n",
    "            x = np.arange(1)  # the label locations\n",
    "            for idx, model_name in enumerate(model_names):\n",
    "                offset = width * multiplier\n",
    "                if is_no_plan:\n",
    "                    rects = ax[col].bar(x + offset, [values[idx]], width * 0.8, label=model_name.capitalize())\n",
    "                    ax[col].bar_label(rects, padding=3, fontsize=12, fmt=\"%.2f\")\n",
    "                else:\n",
    "                    rects = ax[row, col].bar(x + offset, [values[idx]], width * 0.8, label=model_name.capitalize())\n",
    "                    ax[row, col].bar_label(rects, padding=3, fontsize=12, fmt=\"%.2f\")\n",
    "                multiplier += 1\n",
    "\n",
    "\n",
    "            # rects = ax[row, col].bar(model_names, values)\n",
    "            # ax[row, col].bar_label(rects, padding=3, fontsize=8, fmt=\"%.2f\") #\n",
    "            if is_no_plan:\n",
    "                if row == 0:\n",
    "                    ax[col].set_title(f\"{prompt_type.capitalize()} prompt\", y=1, fontsize=12)\n",
    "                ax[col].set_ylim(0, 1.0)\n",
    "                ax[col].xaxis.set_visible(False) \n",
    "                # ax[row, col].tick_params(axis='x', labelsize=12)\n",
    "                ax[col].tick_params(axis='y', labelsize=12)\n",
    "                ax[col].spines[[\"right\", \"top\"]].set_visible(False)\n",
    "                # ax[row, col].set_xlabel(\"Plan length\", fontsize=12)\n",
    "                if col == 0:\n",
    "                    ax[col].set_ylabel(\"Correct \\\"no plan\\\" detection rate\", fontsize=12)\n",
    "\n",
    "                if col == cols -1:\n",
    "                    # ax[row, col].legend(loc=\"best\",fontsize='small') # bbox_to_anchor=(legend_x, legend_height)\n",
    "                    handles, labels = ax[col].get_legend_handles_labels()\n",
    "                # ax[row, col].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            else:\n",
    "                if row == 0:\n",
    "                    ax[row, col].set_title(f\"{prompt_type.capitalize()} prompt\", y=1, fontsize=12)\n",
    "                ax[row, col].set_ylim(0, 1.0)\n",
    "                ax[row, col].xaxis.set_visible(False) \n",
    "                # ax[row, col].tick_params(axis='x', labelsize=12)\n",
    "                ax[row, col].tick_params(axis='y', labelsize=12)\n",
    "                ax[row, col].spines[[\"right\", \"top\"]].set_visible(False)\n",
    "                # ax[row, col].set_xlabel(\"Plan length\", fontsize=12)\n",
    "                if col == 0:\n",
    "                    ax[row, col].set_ylabel(f\"{include_categories[quality]}\", fontsize=12)\n",
    "\n",
    "                if row == rows -1 and col == cols -1:\n",
    "                    # ax[row, col].legend(loc=\"best\",fontsize='small') # bbox_to_anchor=(legend_x, legend_height)\n",
    "                    handles, labels = ax[row, col].get_legend_handles_labels()\n",
    "                # ax[row, col].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "    \n",
    "    if is_no_plan:\n",
    "        fig.legend(handles, labels, bbox_to_anchor=(0.97, 0.9), fontsize=\"medium\", loc='upper right', frameon=False)\n",
    "    else:\n",
    "        fig.legend(handles, labels,bbox_to_anchor=(1.15, 0.6), fontsize=\"large\", loc='upper center', frameon=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name_path, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_planning_chart_multi_rev(llm_bin_input=llm_bin_meta, file_name_path=\"output/plot/planning_all_data.png\", is_no_plan=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Plan Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_planning_chart_multi_rev(llm_bin_input=llm_bin_meta_no_plan, file_name_path=\"output/plot/planning_no_plan.png\", is_no_plan=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is a Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_planning_chart_multi_rev(llm_bin_input=llm_bin_meta_plan, file_name_path=\"output/plot/planning_plan.png\", is_no_plan=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Regression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "\n",
    "llm_bin_meta_reg = {}\n",
    "prompt_stat = {\"verbose\": {\"raw\": []}, \"concise\": {\"raw\": []}}\n",
    "for category in planning_data.keys():\n",
    "    X = []\n",
    "    Y = []\n",
    "    X_model = {}\n",
    "    Y_model = {}\n",
    "    X_0 = []  # no plan case\n",
    "    Y_0 = []  # no plan case\n",
    "    X_model_0 = {}  # no plan case\n",
    "    Y_model_0 = {}  # no plan case\n",
    "\n",
    "    for llm_response_planning_evaluation_unit in planning_data[category]:\n",
    "        llm_model_id = llm_response_planning_evaluation_unit.llm_response_planning_data.llm_response.llm_model_id\n",
    "        if llm_model_id not in X_model:\n",
    "            X_model[llm_model_id] = []\n",
    "            Y_model[llm_model_id] = []\n",
    "            X_model_0[llm_model_id] = []\n",
    "            Y_model_0[llm_model_id] = []\n",
    "\n",
    "        # X\n",
    "        tag = llm_response_planning_evaluation_unit.llm_response_planning_data.pddl_generator_output.planning_datum_tag\n",
    "\n",
    "        prompt_length = len(llm_response_planning_evaluation_unit.llm_response_planning_data.planning_prompt)\n",
    "        prompt_stat[category][\"raw\"].append(prompt_length)\n",
    "\n",
    "        if tag.length_of_sequence > 0:\n",
    "            # 1. sequence length\n",
    "            # 2. Actions\n",
    "            # 3. input parameters\n",
    "            # 4. coupling\n",
    "            # 5. slot-fill\n",
    "            # 6. goals\n",
    "\n",
    "            tmp_x = [\n",
    "                float(tag.length_of_sequence),\n",
    "                float(tag.number_of_agents),\n",
    "                float(tag.input_parameters_per_agent),\n",
    "                float(tag.coupling_of_agents),\n",
    "                float(\n",
    "                    llm_response_planning_evaluation_unit.llm_response_planning_data.pddl_generator_output.agent_info_generator_input.proportion_slot_fillable_variables\n",
    "                ),\n",
    "                float(tag.number_of_goals),\n",
    "                # float(len(llm_response_planning_evaluation_unit.llm_response_planning_data.planning_prompt)),\n",
    "                # float(len(llm_response_planning_evaluation_unit.llm_response_planning_data.llm_response.generated_text)),\n",
    "            ]\n",
    "            X.append(tmp_x)\n",
    "            X_model[llm_model_id].append(tmp_x)\n",
    "        else:\n",
    "            # 1. Actions\n",
    "            # 2. input parameters\n",
    "            # 3. coupling\n",
    "            # 4. slot-fill\n",
    "            # 5. goals\n",
    "            tmp_x = [\n",
    "                float(tag.number_of_agents),\n",
    "                float(tag.input_parameters_per_agent),\n",
    "                float(tag.coupling_of_agents),\n",
    "                float(\n",
    "                    llm_response_planning_evaluation_unit.llm_response_planning_data.pddl_generator_output.agent_info_generator_input.proportion_slot_fillable_variables\n",
    "                ),\n",
    "                float(tag.number_of_goals),\n",
    "                # float(len(llm_response_planning_evaluation_unit.llm_response_planning_data.planning_prompt)),\n",
    "                # float(len(llm_response_planning_evaluation_unit.llm_response_planning_data.llm_response.generated_text)),\n",
    "            ]\n",
    "            X_0.append(tmp_x)\n",
    "            X_model_0[llm_model_id].append(tmp_x)\n",
    "\n",
    "        # Y\n",
    "        sound_planning = 0\n",
    "        valid_planning = 0\n",
    "        optimal_planning = 0\n",
    "\n",
    "        # soundness\n",
    "        if (\n",
    "            llm_response_planning_evaluation_unit.report_soundness is not None\n",
    "            and llm_response_planning_evaluation_unit.report_soundness.determination\n",
    "        ):\n",
    "            sound_planning = 1\n",
    "\n",
    "        # handle no plan case\n",
    "        if (\n",
    "            llm_response_planning_evaluation_unit.llm_response_planning_data.pddl_generator_output.planning_datum_tag.length_of_sequence\n",
    "            == 0\n",
    "        ):  # no plan case\n",
    "            if (llm_response_planning_evaluation_unit.llm_plan is not None) and (\n",
    "                len(llm_response_planning_evaluation_unit.llm_plan) == 0\n",
    "            ):\n",
    "                valid_planning = 1\n",
    "                optimal_planning = 1\n",
    "        else:  # plan exists\n",
    "            if (\n",
    "                llm_response_planning_evaluation_unit.report_validity is not None\n",
    "                and llm_response_planning_evaluation_unit.report_validity.determination\n",
    "            ):\n",
    "                valid_planning = 1\n",
    "            if (\n",
    "                llm_response_planning_evaluation_unit.report_optimality is not None\n",
    "                and llm_response_planning_evaluation_unit.report_optimality.determination\n",
    "            ):\n",
    "                optimal_planning = 1\n",
    "\n",
    "        tmp_y = [sound_planning, valid_planning, optimal_planning]\n",
    "\n",
    "        if tag.length_of_sequence > 0:\n",
    "            Y.append(tmp_y)\n",
    "            Y_model[llm_model_id].append(tmp_y)\n",
    "        else:\n",
    "            Y_0.append(tmp_y)\n",
    "            Y_model_0[llm_model_id].append(tmp_y)\n",
    "\n",
    "    llm_bin_meta_reg[category] = {\n",
    "        \"X_model\": X_model,\n",
    "        \"Y_model\": Y_model,\n",
    "        \"X\": X,\n",
    "        \"Y\": Y,\n",
    "        \"X_model_0\": X_model_0,\n",
    "        \"Y_model_0\": Y_model_0,\n",
    "        \"X_0\": X_0,\n",
    "        \"Y_0\": Y_0,\n",
    "    }\n",
    "\n",
    "\n",
    "for category in prompt_stat.keys():\n",
    "    prompt_stat[category][\"mean\"] = statistics.mean(prompt_stat[category][\"raw\"])\n",
    "    print(prompt_stat[category][\"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "for category in llm_bin_meta_reg.keys():\n",
    "    tmp_data_dict = llm_bin_meta_reg[category]\n",
    "    X = tmp_data_dict[\"X\"]\n",
    "    X_model = tmp_data_dict[\"X_model\"]\n",
    "    X_0 = tmp_data_dict[\"X_0\"]\n",
    "    X_model_0 = tmp_data_dict[\"X_model_0\"]\n",
    "\n",
    "    # normalize\n",
    "    X_1 = np.array(X, dtype=np.float64)\n",
    "    X_n = normalize(X_1, axis=0, norm=\"l2\")\n",
    "\n",
    "    X_1_0 = np.array(X_0, dtype=np.float64)\n",
    "    X_n_0 = normalize(X_1_0, axis=0, norm=\"l2\")\n",
    "\n",
    "    X_model_n = {}\n",
    "    for llm_model_id, data_x in X_model.items():\n",
    "        tmp_1 = np.array(data_x, dtype=np.float64)\n",
    "        X_model_n[llm_model_id] = normalize(tmp_1, axis=0, norm=\"l2\")\n",
    "    \n",
    "    X_model_n_0 = {}\n",
    "    for llm_model_id, data_x in X_model_0.items():\n",
    "        tmp_1 = np.array(data_x, dtype=np.float64)\n",
    "        X_model_n_0[llm_model_id] = normalize(tmp_1, axis=0, norm=\"l2\")\n",
    "\n",
    "    llm_bin_meta_reg[category][\"X_n\"] = X_n\n",
    "    llm_bin_meta_reg[category][\"X_model_n\"] = X_model_n\n",
    "    llm_bin_meta_reg[category][\"X_n_0\"] = X_n_0\n",
    "    llm_bin_meta_reg[category][\"X_model_n_0\"] = X_model_n_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose Y\n",
    "sound_idx = 0\n",
    "valid_idx = 1\n",
    "optimal_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from ai_profiling.helpers.file_helper.file_helper import write_txt_file\n",
    "\n",
    "\n",
    "def get_logistic_regression(llm_bin_meta_reg: Any, group_name: str, output_folder_path: str, has_plan: bool):\n",
    "\n",
    "    for evaluation_idx in range(3):\n",
    "        if evaluation_idx == 0:\n",
    "            evaluation_str = \"Soundness\"\n",
    "        elif evaluation_idx == 1:\n",
    "            evaluation_str = \"Validity\"\n",
    "        elif evaluation_idx == 2:\n",
    "            evaluation_str = \"Optimality\"\n",
    "\n",
    "        print(f\"\\n\\n\\n\\n Evaluation Category: {evaluation_str} \\n\\n\\n\\n\")\n",
    "\n",
    "        for category in llm_bin_meta_reg.keys():\n",
    "            print(f\"Category: {category}\")\n",
    "            X_key = \"X_n\" if has_plan else \"X_n_0\"\n",
    "            X_model_key = \"X_model_n\" if has_plan else \"X_model_n_0\"\n",
    "            Y_key = \"Y\" if has_plan else \"Y_0\"\n",
    "            Y_model_key = \"Y_model\" if has_plan else \"Y_model_0\"\n",
    "\n",
    "            tmp = llm_bin_meta_reg[category]\n",
    "            X_n = tmp[X_key]\n",
    "            X_model_n = tmp[X_model_key]\n",
    "            Y = tmp[Y_key]\n",
    "            Y_model = tmp[Y_model_key]\n",
    "\n",
    "            print(\"\\n\\n\\nSubject: Total\")\n",
    "            logit = sm.Logit(np.array(list(map(lambda arr: arr[evaluation_idx], Y))), X_n)\n",
    "            result = logit.fit_regularized(method=\"l1\", alpha=1)\n",
    "            # result = logit.fit(maxiter=1000)\n",
    "            print(result.summary())\n",
    "            model_name = \"total\"\n",
    "            name = f\"{category}_{model_name}\"\n",
    "\n",
    "            write_txt_file(\n",
    "                file_path=os.path.join(output_folder_path, group_name, (name + \".csv\")), text=result.summary().as_csv()\n",
    "            )\n",
    "\n",
    "            for llm_model_id in X_model_n.keys():\n",
    "                print(f\"\\n\\n\\nSubject: {llm_model_id}\")\n",
    "                x_n = X_model_n[llm_model_id]\n",
    "                y = np.array(list(map(lambda arr: arr[evaluation_idx], Y_model[llm_model_id])))\n",
    "                logit = sm.Logit(y, x_n)\n",
    "                result = logit.fit_regularized(method=\"l1\", alpha=1)\n",
    "                print(result.summary())\n",
    "                tmp_model_name = llm_model_id.split(\"/\")[-1]\n",
    "                name = f\"{category}_{tmp_model_name}\"\n",
    "                write_txt_file(\n",
    "                    file_path=os.path.join(output_folder_path, group_name, evaluation_str, ( name + \".csv\")),\n",
    "                    text=result.summary().as_csv(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_logistic_regression(llm_bin_meta_reg=llm_bin_meta_reg, group_name=\"plan\", output_folder_path=\"output/regression_plan\", has_plan=True)\n",
    "get_logistic_regression(llm_bin_meta_reg=llm_bin_meta_reg, group_name=\"no_plan\", output_folder_path=\"output/regression_plan\", has_plan=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nl2flow_runner (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
